{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Understanding\n",
    "\n",
    "Starts with some more useful regex patterns:\n",
    "\n",
    "`r\"\\bme\\b\"` will match only the word \"me\"  \n",
    "`[A-Z]{1}[a-z]*` will match any title case word.  \n",
    "\n",
    "If you're going to use a pattern several times, then store it with `re.compile()`.\n",
    "\n",
    "Use of pipe operators within a pattern to match several, also use of `pattern.findall()` for multiple matches within a sentence.\n",
    "\n",
    "## Flexibly match intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_dict = {\n",
    "    'goodbye': ['see ya', 'bye'],\n",
    "    'greet': [r'\\bhi\\b', 'hola', 'heya'],\n",
    "    'thankyou': ['appreciate', 'thank', r'\\bta\\b']\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goodbye': re.compile(r'see ya|bye', re.UNICODE),\n",
       " 'greet': re.compile(r'\\bhi\\b|hola|heya', re.UNICODE),\n",
       " 'thankyou': re.compile(r'appreciate|thank|\\bta\\b', re.UNICODE)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile a dict of regex patterns that can look for any of the above pattern matches\n",
    "intent_patterns = {}\n",
    "for key, values in intent_dict.items():\n",
    "    multi_pat = \"|\".join(values)\n",
    "    compiled_pat = re.compile(multi_pat)\n",
    "    # label this flexible pattern with the intent key it came with\n",
    "    intent_patterns[key] = compiled_pat\n",
    "intent_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the intent of a message\n",
    "def find_intent(pat_dict, some_input):\n",
    "    matched = None\n",
    "    for intent, patterns in pat_dict.items():\n",
    "        # Check for a pattern match first\n",
    "        if patterns.search(some_input):\n",
    "            matched = intent\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greet\n",
      "thankyou\n",
      "goodbye\n"
     ]
    }
   ],
   "source": [
    "print(find_intent(intent_patterns, \"hola! Como estas\"))\n",
    "print(find_intent(intent_patterns, \"thankee sai\"))\n",
    "print(find_intent(intent_patterns, \"see ya bud!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respond to the intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {\n",
    "    'default': '...',\n",
    "    'goodbye': 'Have a great day',\n",
    "    'greet': 'Hi there',\n",
    "    'thankyou': \"no problem, that's my job\"\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(string_input, pat_dict, resps):\n",
    "    # get the matched intent\n",
    "    intent = find_intent(pat_dict, string_input.lower())\n",
    "    # Use default as the fll back value\n",
    "    key = \"default\"\n",
    "    if intent in resps:\n",
    "        key = intent\n",
    "    return resps[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Have a great day'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"See ya\", intent_patterns, response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the wrapper function from module 1 that uses a nice display template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update params to include the lookup dicts as default\n",
    "def user_speaks(user_input, pat_dict=intent_patterns, resps=response_dict, user_format=\"USER:\", bot_format=\"BOT:\"):\n",
    "    \"\"\"Passes the user's input to response handler.\"\"\"\n",
    "    time.sleep(0.6)\n",
    "    print(f\"{user_format} {user_input}\")\n",
    "    # update the line below to use the new flexible match functions\n",
    "    resp = answer(user_input, pat_dict, resps)\n",
    "    time.sleep(0.6)\n",
    "    return f\"{bot_format} {resp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: Hi hi cherry pie!\n",
      "BOT: Hi there\n",
      "USER: Ta very much my lovely...\n",
      "BOT: no problem, that's my job\n",
      "USER: Gotta go. Bye bye hunny pie.\n",
      "BOT: Have a great day\n"
     ]
    }
   ],
   "source": [
    "print(user_speaks(\"Hi hi cherry pie!\"))\n",
    "print(user_speaks(\"Ta very much my lovely...\"))\n",
    "print(user_speaks(\"Gotta go. Bye bye hunny pie.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic NER\n",
    "\n",
    "Named Entity Recognition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(string_input):\n",
    "    \"\"\"Searches a string for an indication that a name is being discussed, then search\n",
    "    for a proper noun and return it if found.\"\"\"\n",
    "    # ensure None is returned if no match is found\n",
    "    entity = None\n",
    "    name_pat = re.compile(\"name|call\")\n",
    "    proper_noun_pat = re.compile(\"[A-Z]{1}[a-z]*\")\n",
    "    # look for a sentence about a named entity:\n",
    "    if name_pat.search(string_input):\n",
    "        entity = proper_noun_pat.findall(string_input)\n",
    "        if len(entity) > 0:\n",
    "            # several hits means we need to concatenate values\n",
    "            entity = \" \".join(entity)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jimmy\n",
      "My Jimmy\n"
     ]
    }
   ],
   "source": [
    "print(get_names(\"my name is Jimmy.\"))\n",
    "print(get_names(\"My name is Jimmy.\"))\n",
    "# you can see how this would be limited and won't work with lowering an input string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define respond()\n",
    "def answer_name(str_input):\n",
    "    name = get_names(str_input)\n",
    "    if name is None:\n",
    "        return \"You're mysterious, tell me your name.\"\n",
    "    else:\n",
    "        return f\"Hello, {name}!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update params to include the lookup dicts as default\n",
    "def user_speaks(user_input, pat_dict=intent_patterns, resps=response_dict, user_format=\"USER:\", bot_format=\"BOT:\"):\n",
    "    \"\"\"Passes the user's input to response handler.\"\"\"\n",
    "    time.sleep(0.6)\n",
    "    print(f\"{user_format} {user_input}\")\n",
    "    # update the line below to use the name retrieval funcs\n",
    "    resp = answer_name(user_input)\n",
    "    time.sleep(0.6)\n",
    "    return f\"{bot_format} {resp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: i am called John Snow\n",
      "BOT: Hello, John Snow!\n",
      "USER: my name is Spartacus\n",
      "BOT: Hello, Spartacus!\n",
      "USER: My name is Spartacus\n",
      "BOT: Hello, My Spartacus!\n"
     ]
    }
   ],
   "source": [
    "print(user_speaks(\"i am called John Snow\"))\n",
    "print(user_speaks(\"my name is Spartacus\"))\n",
    "print(user_speaks(\"My name is Spartacus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordvec with spaCy\n",
    "\n",
    "Great little intro on word vectors, where tokens - floats - are assigned to words, word parts, letters or sentences. These can then be used within ML workflows. spaCy makes several wordvec models available. Here we are using `en_core_web_sm` which is trained upon a large corpus with the GloVe algorithm.\n",
    "\n",
    "Tokens can be compared to others using their cosine similarity:\n",
    "\n",
    "* Vector directions point in same direction = 1\n",
    "* Vector directions are perpindicular = 0 \n",
    "* Vector directions are opposite = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py-chatbots/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim = nlp.vocab.vectors_length\n",
    "n_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hey Ho, ah let's go!"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the nlp model on a string to get tokens:\n",
    "doc = nlp(\"Hey Ho, ah let's go!\")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey: [ 2.9      0.48218 -2.2693   0.27522 -7.1124   1.2409  -0.43371]\n",
      "Ho: [-1.9577  -3.629   -4.1803   0.75524  2.439    4.1769  -1.2797 ]\n",
      ",: [-3.3899  -4.7034  -0.56101  1.2291   4.3298  -1.0775  -1.3006 ]\n",
      "ah: [ 3.5059   2.9413  -0.30366 -0.53069 -3.0985   3.9806  -2.8103 ]\n",
      "let: [ 8.0705   6.2403  -5.6268  -0.6813  -3.603    2.8543  -0.82774]\n",
      "'s: [ 3.3163   9.7209  -3.1254  -5.1013  12.248    0.74676 -2.2017 ]\n",
      "go: [ 1.484   8.3944 -8.3806  3.2081 -4.2582  1.9773 -2.7806]\n",
      "!: [ 5.0891  -3.3753  -4.2695  -4.8156   3.8904   6.2171   0.26271]\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token}: {token.vector[:7]}\")\n",
    "# showing the first 7 word vectors for the sentence tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc[0].vector) == n_dim\n",
    "# you can see that each token has n_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>old-name</th>\n",
       "      <th>query-split</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sql</th>\n",
       "      <th>variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>[{'text': 'list all the flights that arrive at...</td>\n",
       "      <td>[SELECT DISTINCT FLIGHTalias0.FLIGHT_ID FROM A...</td>\n",
       "      <td>[{'example': 'MKE', 'location': 'unk', 'name':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>[{'text': 'give me the flights leaving city_na...</td>\n",
       "      <td>[SELECT DISTINCT FLIGHTalias0.FLIGHT_ID FROM A...</td>\n",
       "      <td>[{'example': 'BOSTON', 'location': 'unk', 'nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>[{'text': 'what is the most expensive one way ...</td>\n",
       "      <td>[SELECT DISTINCT FAREalias0.FARE_ID FROM AIRPO...</td>\n",
       "      <td>[{'example': 'BOSTON', 'location': 'unk', 'nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>[{'text': 'what flights return from city_name1...</td>\n",
       "      <td>[SELECT DISTINCT FLIGHTalias0.FLIGHT_ID FROM A...</td>\n",
       "      <td>[{'example': 'PHILADELPHIA', 'location': 'unk'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "      <td>[{'text': 'can you list all flights from city_...</td>\n",
       "      <td>[SELECT DISTINCT FLIGHTalias0.FLIGHT_ID FROM A...</td>\n",
       "      <td>[{'example': 'CHICAGO', 'location': 'unk', 'na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comments old-name query-split  \\\n",
       "0       []                train   \n",
       "1       []                train   \n",
       "2       []                train   \n",
       "3       []                train   \n",
       "4       []                train   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [{'text': 'list all the flights that arrive at...   \n",
       "1  [{'text': 'give me the flights leaving city_na...   \n",
       "2  [{'text': 'what is the most expensive one way ...   \n",
       "3  [{'text': 'what flights return from city_name1...   \n",
       "4  [{'text': 'can you list all flights from city_...   \n",
       "\n",
       "                                                 sql  \\\n",
       "0  [SELECT DISTINCT FLIGHTalias0.FLIGHT_ID FROM A...   \n",
       "1  [SELECT DISTINCT FLIGHTalias0.FLIGHT_ID FROM A...   \n",
       "2  [SELECT DISTINCT FAREalias0.FARE_ID FROM AIRPO...   \n",
       "3  [SELECT DISTINCT FLIGHTalias0.FLIGHT_ID FROM A...   \n",
       "4  [SELECT DISTINCT FLIGHTalias0.FLIGHT_ID FROM A...   \n",
       "\n",
       "                                           variables  \n",
       "0  [{'example': 'MKE', 'location': 'unk', 'name':...  \n",
       "1  [{'example': 'BOSTON', 'location': 'unk', 'nam...  \n",
       "2  [{'example': 'BOSTON', 'location': 'unk', 'nam...  \n",
       "3  [{'example': 'PHILADELPHIA', 'location': 'unk'...  \n",
       "4  [{'example': 'CHICAGO', 'location': 'unk', 'na...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download ATIS dataset\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "#URL = 'https://raw.githubusercontent.com/jkkummerfeld/text2sql-data/master/data/atis.json'\n",
    "#data = json.loads(requests.get(URL).text)\n",
    "## Flattening JSON data\n",
    "#ATIS = pd.json_normalize(data)\n",
    "#ATIS.head()\n",
    "# This source did not have the labels from what I could see, so going with kaggle instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i want to fly from boston at 838 am and arriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>what flights are available from pittsburgh to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atis_flight_time</td>\n",
       "      <td>what is the arrival time in san francisco for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>cheapest airfare from tacoma to orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label                                               text\n",
       "0       atis_flight   i want to fly from boston at 838 am and arriv...\n",
       "1       atis_flight   what flights are available from pittsburgh to...\n",
       "2  atis_flight_time   what is the arrival time in san francisco for...\n",
       "3      atis_airfare            cheapest airfare from tacoma to orlando\n",
       "4      atis_airfare   round trip fares from pittsburgh to philadelp..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyprojroot import here\n",
    "# there is a kaggle api, but overkill for this project. Source is:\n",
    "# https://www.kaggle.com/datasets/hassanamin/atis-airlinetravelinformationsystem?resource=download\n",
    "colnames = [\"label\", \"text\"]\n",
    "ATIS = pd.read_csv(os.path.join(here(), \"data\", \"atis_intents.csv\"), names = colnames)\n",
    "sentences = ATIS.text\n",
    "n_sent = len(sentences)\n",
    "ATIS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4978, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare a 2D array for storing the vectors\n",
    "import numpy as np\n",
    "vec_array = np.zeros((n_sent, n_dim))\n",
    "print(np.shape(vec_array))\n",
    "vec_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0826674 , -0.58716798, -2.1964817 , ..., -1.25990617,\n",
       "        -2.6429491 ,  1.24336207],\n",
       "       [-1.80790913,  1.00080669, -3.05921483, ..., -1.52719319,\n",
       "        -2.36632752,  1.1796701 ],\n",
       "       [-1.36993992,  0.49113077,  0.07254934, ..., -1.3198179 ,\n",
       "        -2.0484488 ,  2.16480947],\n",
       "       ...,\n",
       "       [-1.82230973, -1.06588328, -2.15213466, ..., -2.93899107,\n",
       "        -2.00138211, -1.13957   ],\n",
       "       [-2.00526071,  2.67443204, -2.5772748 , ..., -0.08352997,\n",
       "        -2.17978454,  0.47018856],\n",
       "       [-1.33432257,  3.42474079, -2.36559343, ...,  0.34180367,\n",
       "        -3.09680247,  2.61888719]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass all the sentences to spacy to calclate the word vectors, storing in our array\n",
    "for row, sentence in enumerate(sentences):\n",
    "    doc = nlp(sentence)\n",
    "    vec_array[row, :] = doc.vector\n",
    "vec_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an SVM to recognise intents\n",
    "\n",
    "Various approaches to cosine similarity are discussed, but the exercises are about fitting a support vector classifier to our data. Data is labelled and with a train test split as is usual, so prepare this now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py-chatbots')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dddb5cd0d12278ac213127e29759590790bdd2e1e3f009e6cf1f79712aa83327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
